{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2986807e-7850-404f-a957-eaeb16371d24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ProbVLM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb セル 1\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmunch\u001b[39;00m \u001b[39mimport\u001b[39;00m Munch \u001b[39mas\u001b[39;00m mch\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mds\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_coco_dataloaders, prepare_flickr_dataloaders, prepare_cub_dataloaders, prepare_flo_dataloaders\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnetworks\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/ds/__init__.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"Modules for multi-modal datasets\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39mPCME\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mCopyright (c) 2021-present NAVER Corp.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mMIT license\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mProbVLM\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mds\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_cub_dataloaders\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mProbVLM\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mds\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_coco_dataloaders, prepare_flickr_dataloaders\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mProbVLM\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mds\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m prepare_fashion_dataloaders\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ProbVLM'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from os.path import join as ospj\n",
    "from os.path import expanduser\n",
    "from munch import Munch as mch\n",
    "import numpy as np\n",
    "\n",
    "from ds import prepare_coco_dataloaders, prepare_flickr_dataloaders, prepare_cub_dataloaders, prepare_flo_dataloaders\n",
    "\n",
    "from utils import *\n",
    "from networks import *\n",
    "from train_probVLM import *\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb7f39-293e-48fe-bd3b-da616157f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "Loading COCO Caption: n_images 113287 n_captions 566435...\n",
      "loading annotations into memory...\n",
      "Done (t=0.46s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading COCO Caption: n_images 1000 n_captions 5000...\n",
      "loading annotations into memory...\n",
      "Done (t=0.41s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading COCO Caption: n_images 5000 n_captions 25000...\n"
     ]
    }
   ],
   "source": [
    "dataset = 'coco' # coco or flickr\n",
    "data_dir = ospj('../../dataset', dataset) # e.g. ospj(expanduser('~'), 'Documents', 'jm', 'data', dataset)\n",
    "dataloader_config = mch({\n",
    "    'batch_size': 32,\n",
    "    'random_erasing_prob': 0.,\n",
    "    'traindata_shuffle': True\n",
    "})\n",
    "loaders = load_data_loader(dataset, data_dir, dataloader_config, num_workers=12)\n",
    "coco_train_loader, coco_valid_loader, coco_test_loader = loaders['train'], loaders['val'], loaders['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da29997-5483-4fa0-b927-74b38dc36cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py:33: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 4 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    }
   ],
   "source": [
    "# clip_net = load_model('cuda')\n",
    "CLIP_Net = load_model(device='cuda', model_path=None)\n",
    "ProbVLM_Net = BayesCap_for_CLIP(\n",
    "    inp_dim=512,\n",
    "    out_dim=512,\n",
    "    hid_dim=256,\n",
    "    num_layers=3,\n",
    "    p_drop=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1513f40-28d1-4d4d-8d9b-e113c8cd4183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17702 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  11%|█▏        | 2001/17702 [12:54<1:41:19,  2.58batch/s, loss=2.45]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. loss: 0.3949558953756182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating ...: 100%|██████████| 157/157 [01:04<00:00,  2.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. MSE: 1.699514389038086 | Avg. MAE: 1.0173567533493042\n",
      "current score: 1.0173567533493042 | Last best score: 100000000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  11%|█▏        | 2001/17702 [12:14<1:36:01,  2.72batch/s, loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. loss: 0.25313159243263994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  11%|█▏        | 2001/17702 [12:08<1:35:18,  2.75batch/s, loss=1.74]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. loss: 0.2090312448305917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  11%|█▏        | 2001/17702 [12:05<1:34:55,  2.76batch/s, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. loss: 0.1703449706615883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  11%|█▏        | 2001/17702 [12:01<1:34:22,  2.77batch/s, loss=1.34]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. loss: 0.1505195981175896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:   1%|          | 154/17702 [00:58<1:51:29,  2.62batch/s, loss=1.3] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb セル 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m train_ProbVLM(\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     CLIP_Net,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     ProbVLM_Net,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     coco_train_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     coco_valid_loader,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     Cri \u001b[39m=\u001b[39;49m TempCombLoss(),\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mFloatTensor,\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     init_lr\u001b[39m=\u001b[39;49m\u001b[39m8e-5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     num_epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     eval_every\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     ckpt_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../../models/\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     T1\u001b[39m=\u001b[39;49m\u001b[39m1e0\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     T2\u001b[39m=\u001b[39;49m\u001b[39m1e-4\u001b[39;49m\n\u001b[1;32m     <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f496e7465722d434c4950227d@ssh-remote%2Bdgx-station-a100/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_ProbVLM_CLIP.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m/workspace/Inter-CLIP/Inter-ProbVLM/ProbVLM/src/train_probVLM.py:61\u001b[0m, in \u001b[0;36mtrain_ProbVLM\u001b[0;34m(CLIP_Net, BayesCap_Net, train_loader, eval_loader, Cri, device, dtype, init_lr, num_epochs, eval_every, ckpt_path, cross_modal_lambda, T1, T2)\u001b[0m\n\u001b[1;32m     59\u001b[0m xI, xT  \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device), batch[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdbg: \u001b[39m\u001b[39m'\u001b[39m, xI\u001b[39m.\u001b[39mshape, xT\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     62\u001b[0m     xfI, xfT \u001b[39m=\u001b[39m CLIP_Net(xI, xT)\n\u001b[1;32m     63\u001b[0m \u001b[39m# xI, xT = xI.type(dtype), xT.type(dtype)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39m# pass them through the network\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule(\u001b[39m*\u001b[39minputs[\u001b[39m0\u001b[39m], \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodule_kwargs[\u001b[39m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplicate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice_ids[:\u001b[39mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparallel_apply(replicas, inputs, module_kwargs)\n\u001b[1;32m    186\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather(outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparallel_apply\u001b[39m(\u001b[39mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[39mreturn\u001b[39;00m parallel_apply(replicas, inputs, kwargs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice_ids[:\u001b[39mlen\u001b[39;49m(replicas)])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py:102\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    100\u001b[0m         thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    101\u001b[0m     \u001b[39mfor\u001b[39;00m thread \u001b[39min\u001b[39;00m threads:\n\u001b[0;32m--> 102\u001b[0m         thread\u001b[39m.\u001b[39;49mjoin()\n\u001b[1;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     _worker(\u001b[39m0\u001b[39m, modules[\u001b[39m0\u001b[39m], inputs[\u001b[39m0\u001b[39m], kwargs_tup[\u001b[39m0\u001b[39m], devices[\u001b[39m0\u001b[39m], streams[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_ProbVLM(\n",
    "    CLIP_Net,\n",
    "    ProbVLM_Net,\n",
    "    coco_train_loader,\n",
    "    coco_valid_loader,\n",
    "    Cri = TempCombLoss(),\n",
    "    device='cuda',\n",
    "    dtype=torch.cuda.FloatTensor,\n",
    "    init_lr=8e-5,\n",
    "    num_epochs=500,\n",
    "    eval_every=5,\n",
    "    ckpt_path='../../models/',\n",
    "    T1=1e0,\n",
    "    T2=1e-4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
